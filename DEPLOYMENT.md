# Deployment Guide - Smart Factory Analytics

## ðŸš€ Deployment Options

This guide covers multiple deployment strategies for the Smart Factory Analytics platform.

---

## Option 1: Vercel (Recommended for Frontend)

### Prerequisites
- Vercel account
- GitHub repository

### Steps

1. **Prepare Frontend for Deployment**

Update `frontend/next.config.js`:
```javascript
module.exports = {
  reactStrictMode: true,
  env: {
    API_URL: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000',
  },
  // For static export (optional)
  output: 'standalone',
}
```

2. **Push to GitHub**
```bash
git init
git add .
git commit -m "Initial commit"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/smart-factory-analytics.git
git push -u origin main
```

3. **Deploy on Vercel**
- Go to https://vercel.com
- Click "New Project"
- Import your GitHub repo
- Configure:
  - Framework: Next.js
  - Root Directory: `frontend`
  - Build Command: `npm run build`
  - Install Command: `npm install`

4. **Environment Variables**
Add in Vercel dashboard:
```
NEXT_PUBLIC_API_URL=YOUR_BACKEND_API_URL
```

5. **Deploy**
Click "Deploy" and wait for completion.

---

## Option 2: Railway (Recommended for Backend)

### Deploy FastAPI Backend

1. **Create Railway Account**
Go to https://railway.app

2. **Create New Project**
- Click "New Project"
- Select "Deploy from GitHub repo"
- Choose your repository

3. **Configure Backend**

Create `railway.json` in project root:
```json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "cd backend && uvicorn main:app --host 0.0.0.0 --port $PORT",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

4. **Add Environment Variables**
- `PORT` (auto-generated by Railway)
- `PYTHONUNBUFFERED=1`

5. **Generate Domain**
Railway provides a domain automatically.

---

## Option 3: Docker Deployment

### Create Dockerfiles

**Backend Dockerfile** (`backend/Dockerfile`):
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY backend/ ./backend/
COPY data/ ./data/
COPY simulate_sensor_data.py .
COPY generate_reports.py .

WORKDIR /app/backend

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Frontend Dockerfile** (`frontend/Dockerfile`):
```dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

FROM node:18-alpine AS runner

WORKDIR /app

COPY --from=builder /app/next.config.js ./
COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

EXPOSE 3000

CMD ["node", "server.js"]
```

**Docker Compose** (`docker-compose.yml`):
```yaml
version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./reports:/app/reports
    environment:
      - PYTHONUNBUFFERED=1

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend
```

**Run with Docker:**
```bash
docker-compose up --build
```

---

## Option 4: AWS Deployment

### Backend on AWS Lambda

1. **Install Mangum** (ASGI adapter for Lambda):
```bash
pip install mangum
```

2. **Update `backend/main.py`**:
```python
from mangum import Mangum

# ... existing code ...

handler = Mangum(app)
```

3. **Deploy with AWS SAM or Serverless Framework**

**serverless.yml**:
```yaml
service: smart-factory-api

provider:
  name: aws
  runtime: python3.11
  stage: prod
  region: us-east-1

functions:
  api:
    handler: backend/main.handler
    events:
      - http:
          path: /{proxy+}
          method: ANY
```

### Frontend on AWS Amplify

1. Connect GitHub repository
2. Configure build settings:
```yaml
version: 1
frontend:
  phases:
    preBuild:
      commands:
        - cd frontend
        - npm ci
    build:
      commands:
        - npm run build
  artifacts:
    baseDirectory: frontend/.next
    files:
      - '**/*'
  cache:
    paths:
      - frontend/node_modules/**/*
```

---

## Option 5: Heroku Deployment

### Backend on Heroku

1. **Create `Procfile`**:
```
web: cd backend && uvicorn main:app --host 0.0.0.0 --port $PORT
```

2. **Create `runtime.txt`**:
```
python-3.11.0
```

3. **Deploy**:
```bash
heroku create smart-factory-backend
git push heroku main
```

### Frontend on Heroku

1. **Update `package.json` in root**:
```json
{
  "scripts": {
    "install": "cd frontend && npm install",
    "build": "cd frontend && npm run build",
    "start": "cd frontend && npm start"
  }
}
```

2. **Deploy**:
```bash
heroku create smart-factory-frontend
git push heroku main
```

---

## Environment Variables

### Backend
```bash
PORT=8000
PYTHONUNBUFFERED=1
```

### Frontend
```bash
NEXT_PUBLIC_API_URL=https://your-api-domain.com
NODE_ENV=production
```

---

## Post-Deployment Checklist

- [ ] Test all API endpoints
- [ ] Verify CORS settings
- [ ] Check environment variables
- [ ] Test frontend connectivity to backend
- [ ] Monitor error logs
- [ ] Set up monitoring (Sentry, DataDog, etc.)
- [ ] Configure SSL/HTTPS
- [ ] Set up CDN for static assets
- [ ] Enable caching
- [ ] Configure rate limiting

---

## Monitoring & Maintenance

### Backend Monitoring
```python
# Add to main.py
from fastapi.middleware.cors import CORSMiddleware
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.middleware("http")
async def log_requests(request, call_next):
    logger.info(f"{request.method} {request.url}")
    response = await call_next(request)
    logger.info(f"Status: {response.status_code}")
    return response
```

### Recommended Tools
- **Monitoring**: DataDog, New Relic, or Prometheus
- **Error Tracking**: Sentry
- **Logging**: LogDNA, Papertrail
- **Uptime Monitoring**: UptimeRobot, Pingdom

---

## Scaling Considerations

### Horizontal Scaling
- Use load balancers (AWS ALB, Nginx)
- Deploy multiple backend instances
- Implement caching (Redis)

### Vertical Scaling
- Increase instance size
- Optimize ML model loading
- Use model caching

### Database Optimization
- Switch from SQLite to PostgreSQL
- Implement connection pooling
- Add database indexes

---

## Troubleshooting

### Common Issues

**CORS Errors:**
```python
# In backend/main.py
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://your-frontend-domain.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**Model Loading Issues:**
```python
# Ensure models are in correct path
MODEL_DIR = os.path.join(os.path.dirname(__file__), "ml")
```

**Environment Variable Issues:**
- Check `.env` files are properly loaded
- Verify Vercel/Railway environment settings
- Use `python-dotenv` for local development

---

## Security Best Practices

1. **API Rate Limiting**
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.get("/predict_failure")
@limiter.limit("100/minute")
async def predict_failure():
    # ...
```

2. **Environment Variables**
- Never commit `.env` files
- Use secrets management (AWS Secrets Manager, Vercel Secrets)

3. **HTTPS Only**
- Enforce HTTPS in production
- Use secure headers

---

## CI/CD Pipeline

See `.github/workflows/deploy.yml` for automated deployment.

---

## Support

For deployment issues:
- Check logs in your deployment platform
- Review error messages
- Consult platform documentation
- Open an issue on GitHub

---

## Cost Estimates

### Vercel (Frontend)
- **Hobby**: Free (personal projects)
- **Pro**: $20/month (commercial use)

### Railway (Backend)
- **Free**: $5 credit/month
- **Developer**: $5 base + usage

### AWS (Full Stack)
- **Estimate**: $20-50/month
- Depends on traffic and resources

### Heroku
- **Free**: Limited dyno hours
- **Hobby**: $7/month per dyno

---

Happy Deploying! ðŸš€
